# -*- coding: utf-8 -*-
"""Baseline-UAIC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19NFpiXvRwW21lqrtAJCf0-K3-PNcfdPl
"""

!nvidia-smi

import os
import numpy as np
from tqdm import tqdm
import json
import glob
import re
import pandas as pd
import random
import cv2
import shutil

"""#Setup"""

!git clone https://github.com/PaddlePaddle/PaddleOCR

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/PaddleOCR

!python -m pip install paddlepaddle-gpu==0.0.0.post113 -f https://www.paddlepaddle.org.cn/whl/linux/gpu/develop.html

!pip install -r requirements.txt

"""#Download data"""

!pip install -U --no-cache-dir gdown --pre

## Download training data
!gdown --id 1NJJA1A8I2Xj5-107E3DFohBNzjWyaaf7
!unzip uaic2022_training_data_update.zip -d dataset

## Download Public Valid data
!gdown --id 1frwoaHR24ETHKf4aBQbce6wSoZO-Bi80
!unzip uaic2022_public_valid.zip -d dataset

"""#Train

## Train model detection

### Preprocess for train model detection
"""

def convert(src):
    f = open(src)
    label = json.load(f)
    for item in label:
      item['transcription'] = item['text']
      del item['text']
    label_str = json.dumps(label)
    return label_str

"""Convert to format PaddleOCR"""

root_img = './dataset/uaic2022_training_data/images/'
root_label = glob.glob('./dataset/uaic2022_training_data/labels/*')
random.shuffle(root_label)
num_imgs = len(root_label)

train_ratio = 0.7
val_ratio = 0.3

train_idx_start = int(num_imgs*train_ratio)
val_idx_start = int(num_imgs*(train_ratio))

os.makedirs('./dataset/det/train')
os.makedirs('./dataset/det/val')

train_label = open("./dataset/det/train_label.txt","w")
val_label = open("./dataset/det/val_label.txt","w")

output = './dataset/det'

for idx, file in enumerate(root_label):
    data = convert(file)
    img_name = os.path.basename(file).split('.')[0] + '.jpg'

    if idx < val_idx_start:
      shutil.copy(os.path.join(root_img,img_name), os.path.join(output,'train',img_name))
      train_label.write( 'train/'+img_name+ '\t'+f'{data}' + '\n')
    else:
      shutil.copy(os.path.join(root_img,img_name), os.path.join(output,'val',img_name))
      val_label.write( 'val/'+img_name+ '\t'+f'{data}' + '\n')

"""Download pretrain """

!wget https://paddleocr.bj.bcebos.com/dygraph_v2.1/en_det/det_r50_db%2B%2B_icdar15_train.tar -P ./pretrain_models
!tar -xf ./pretrain_models/det_r50_db++_icdar15_train.tar -C ./pretrain_models

"""### Training"""

!python3 tools/train.py -c ./configs/det/det_r50_db++_icdar15.yml -o   \
         Global.pretrained_model=./pretrain_models/det_r50_db++_icdar15_train/best_accuracy  \
         Global.epoch_num=100  \
         Global.save_inference_dir=uaic2022  \
         Global.save_epoch_step=2 \
        Train.dataset.data_dir=./dataset/det/  \
        Train.dataset.label_file_list=['./dataset/det/train_label.txt'] \
        Train.loader.batch_size_per_card=8  \
        Eval.dataset.data_dir=./dataset/det/  \
        Eval.dataset.label_file_list=['./dataset/det/val_label.txt']

"""##Train model recognition

### Preprocess for train model recognition
"""

def order_points(pts):
    if isinstance(pts, list):
        pts = np.asarray(pts, dtype='float32')
    rect = np.zeros((4, 2), dtype='float32')
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    return rect

def perspective_transform(img, pts):
    rect = order_points(pts)
    (tl, tr, br, bl) = rect
    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    maxWidth = max(int(widthA), int(widthB))

    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    maxHeight = max(int(heightA), int(heightB))

    dst = np.array([
            [0, 0],
            [maxWidth - 1, 0],
            [maxWidth - 1, maxHeight - 1],
            [0, maxHeight - 1]], dtype = "float32")

    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(img, M, (maxWidth, maxHeight))
    return warped

def crop(train_label_path, output_path):
  train_label = open(train_label_path,'r') 
  train_file_list = train_label.readlines()
  crop_label = open(output_path, 'w', encoding="utf-8")

  count=0
  for line in tqdm(train_file_list):
      file_name, labels = line.strip().split('\t')
      labels = json.loads(labels)
      img_path = os.path.join(root_dir, file_name)
      image = cv2.imread(img_path)
      id=0
      for label in labels:
        pts = label['points']
        transcription = label['transcription']

        try:
          pts = [[int(x[0]), int(x[1])] for x in pts]
        except:
          continue

        if transcription == "###" or transcription == '#':
          continue
        
        cropped_img = perspective_transform(image, pts)
        img_crop_name = os.path.basename(file_name).split('.')[0] + '_' + str(id) + '.jpg'
        
        cv2.imwrite(os.path.join(output_path ,'img', img_crop_name), cropped_img)
        crop_label.write(f"img/{img_crop_name}\t{transcription}\n")
      
        id += 1
        count += 1
      
  print('Total box:', count)

"""Crop text box"""

root_dir = '/content/PaddleOCR/dataset/det'

outpath = './dataset/rec_data'

if (not os.path.exists(outpath + '/img')):
  os.makedirs(outpath + '/img')

output_train=os.path.join(outpath,'train_crop.txt')
crop('/content/PaddleOCR/dataset/det/train_label.txt', output_train)

output_val=os.path.join(outpath,'val_crop.txt')
crop('/content/PaddleOCR/dataset/det/val_label.txt', output_val)

## Download pretrain 
!wget https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/rec_r50_vd_srn_train.tar -P ./pretrain_models
!tar -xf ./pretrain_models/rec_r50_vd_srn_train.tar -C ./pretrain_models

## get dict vietnamese 
!wget https://raw.githubusercontent.com/hungcao0402/PaddleOCR-Vietnamese/master1/ppocr/utils/dict/vi_vietnam.txt

"""### Training"""

!python3 tools/train.py -c ./configs/rec/rec_r50_fpn_srn.yml  \
                        -o Global.pretrained_model=./pretrain_models/rec_r50_vd_srn_train/best_accuracy  \
                            Global.character_dict_path=vi_vietnam.txt \
                            Global.epoch_num=6  \
                            Global.save_epoch_step=2 \
                            Train.dataset.name='SimpleDataSet'  \
                            Train.dataset.data_dir=/content/PaddleOCR/dataset/rec_data  \
                            Train.dataset.label_file_list=['./dataset/rec_data/train_crop.txt'] \
                            Eval.dataset.name='SimpleDataSet'  \
                            Eval.dataset.data_dir=/content/PaddleOCR/dataset/rec_data  \
                            Eval.dataset.label_file_list=['./dataset/rec_data/val_crop.txt']

"""#Evaluation

## Evaluate detection
"""

!python3 tools/eval.py -c ./configs/det/det_r50_db++_icdar15.yml  \
                       -o Global.pretrained_model=./output/det_r50_icdar15/latest.pdparams  \
                          Eval.dataset.data_dir=./dataset/det  \
                          Eval.dataset.label_file_list=['./dataset/det/val_label.txt']

"""## Evaluate recognition

"""

!python3 tools/eval.py -c ./configs/rec/rec_r50_fpn_srn.yml  \
                       -o Global.checkpoints=./output/rec/srn_new/latest \
                          Global.character_type=ch  \
                          Global.character_dict_path=./vi_vietnam.txt \
                          Eval.dataset.name='SimpleDataSet'  \
                          Eval.dataset.data_dir=./dataset/rec_data  \
                          Eval.dataset.label_file_list=['./dataset/rec_data/val_crop.txt']

"""#Convert to inference model"""

## Export detection model
!python3 tools/export_model.py -c ./configs/det/det_r50_db++_icdar15.yml  \
                               -o Global.pretrained_model=./output/det_r50_icdar15/latest \
                                  Global.save_inference_dir=./inference/det

## Export recognition model
!python3 tools/export_model.py -c ./configs/rec/rec_r50_fpn_srn.yml  \
                               -o Global.pretrained_model=./output/rec/srn_new/latest \
                                  Global.character_dict_path=./vi_vietnam.txt \
                                  Global.save_inference_dir=./inference/rec

"""Sau khi convert xong thì thử predict """

#predict detection
!python3 tools/infer/predict_det.py --use_gpu=True \
                                    --det_model_dir="./inference/det"  \
                                    --image_dir=./dataset/uaic2022_trainset_demo/images/im0012.jpg

#predict recognition
!python3 tools/infer/predict_rec.py \
          --image_dir="./dataset/rec_data/img/im0001_0.jpg" \
          --rec_model_dir="./inference/rec/" --rec_image_shape="1,64,256" \
          --rec_algorithm="SRN"  \
          --rec_char_dict_path="./vi_vietnam.txt" --use_space_char=False

"""#Text Detection and Recognition Inference Concatenation"""

#get font to visualize
!gdown --id 1y5ijIAEOtHR20TCSKETO-9XHH-veCGID

!python3 ./tools/infer/predict_system.py  \
                    --use_gpu=True  \
                    --det_model_dir="./inference/det"  \
                    --rec_algorithm="SRN" \
                    --rec_model_dir="./inference/rec/"  \
                    --rec_image_shape="1,64,256"  \
                    --drop_score=0.001  \
                    --image_dir="./dataset/det/val/" \
                    --rec_char_dict_path="./vi_vietnam.txt" \
                    --use_space_char=False  \
                    --vis_font_path=font-times-new-roman.ttf

"""# Evaluate E2E"""

#convert to format paddle eval e2e
!python3 tools/end2end/convert_ppocr_label.py --mode=gt --label_path=./dataset/det/val_label.txt --save_folder=save_gt_label
!python3 tools/end2end/convert_ppocr_label.py --mode=pred --label_path=./inference_results/system_results.txt --save_folder=save_infer

!python3 tools/end2end/eval_end2end.py ./save_gt_label/ ./save_infer/

"""# Convert To submit

Run inference cho tập test sau đó convert về format yêu cầu rồi zip lại và nộp
"""

!python3 tools/end2end/convert_ppocr_label.py --mode=pred \
                                              --label_path=./inference_results/system_results.txt \
                                              --save_folder=save_infer

root = glob.glob('./save_infer/*')
os.mkdir('submit')
for file in root:
    file_name = os.path.basename(file).replace('.jpg','')
    f = open(file,'r')
    lines = f.readlines()

    output = open('submit/'+file_name,'w')
    for line in lines:
        line=line.strip()
        label = line.split('\t')
        bbox = label[:8]
        trans = label[-1]
        data = ','.join(bbox)+ ',' +trans+'\n'
        output.write(data)

!zip -j submit.zip submit/*